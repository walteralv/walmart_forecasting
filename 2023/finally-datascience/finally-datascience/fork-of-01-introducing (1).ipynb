{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:34.667543Z",
     "iopub.status.busy": "2023-09-13T01:48:34.667100Z",
     "iopub.status.idle": "2023-09-13T01:48:38.294134Z",
     "shell.execute_reply": "2023-09-13T01:48:38.293119Z",
     "shell.execute_reply.started": "2023-09-13T01:48:34.667507Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import plotly.express as px\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random_state = 1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:38.296447Z",
     "iopub.status.busy": "2023-09-13T01:48:38.296002Z",
     "iopub.status.idle": "2023-09-13T01:48:38.350057Z",
     "shell.execute_reply": "2023-09-13T01:48:38.348825Z",
     "shell.execute_reply.started": "2023-09-13T01:48:38.296407Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/forecasting-problem-unt/train_pandas.csv').sort_values('fecha').reset_index(drop=True)\n",
    "test = pd.read_csv('/kaggle/input/forecasting-problem-unt/test_pandas.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:38.352007Z",
     "iopub.status.busy": "2023-09-13T01:48:38.351610Z",
     "iopub.status.idle": "2023-09-13T01:48:38.360597Z",
     "shell.execute_reply": "2023-09-13T01:48:38.359824Z",
     "shell.execute_reply.started": "2023-09-13T01:48:38.351972Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = train['total_calls']\n",
    "x_train = train.drop('total_calls', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:38.363703Z",
     "iopub.status.busy": "2023-09-13T01:48:38.362944Z",
     "iopub.status.idle": "2023-09-13T01:48:38.377344Z",
     "shell.execute_reply": "2023-09-13T01:48:38.375975Z",
     "shell.execute_reply.started": "2023-09-13T01:48:38.363669Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_get_score_cv(x_train: pd.DataFrame, y_train: pd.Series, models, \n",
    "                       pipeline_engine: Pipeline, features_selected: list=None,\n",
    "                       k=5, random_state=199) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Obtiente el AUC como métrica usando cross validation kfold. El cross validation sirve para simular como \n",
    "    el modelo reacciona a datos no observados.\n",
    "    \n",
    "    Input:\n",
    "    x_train[pd.DataFrame]: dataframe que contiene las variables explicativas a entrar en el modelo.\n",
    "    y_train[pd.Series]: Vector que contiene la variable respuesta.\n",
    "    models[dict]: Diccionario con los modelos a ser entrenados y evaluados.\n",
    "    pipeline_engine[Pipeline]: sklearn pipeline --> funciones a ser procesadas en el conjunto de entrenamiento\n",
    "    k[int]: número de folds en el cross validation\n",
    "    \n",
    "    Return:\n",
    "    Un dataframe con los modelos y la métrica para cada modelo\n",
    "    \"\"\"\n",
    "    if features_selected is None:\n",
    "        features_selected = x_train.columns\n",
    "        \n",
    "    kf = TimeSeriesSplit(n_splits=k)\n",
    "    result = np.zeros((len(models), 1))\n",
    "    \n",
    "    for i,model in enumerate(models.keys()):\n",
    "    \n",
    "        mape_metric = []\n",
    "\n",
    "        learner = models[model]\n",
    "        print(f'Model: {list(models.keys())[i]}')\n",
    "        for fold, (id_train, id_test) in enumerate(kf.split(x_train, y_train)):\n",
    "\n",
    "            Xt = x_train.iloc[id_train]; yt = y_train.iloc[id_train]\n",
    "            Xv = x_train.iloc[id_test]; yv = y_train.iloc[id_test]\n",
    "            if pipeline_engine != None:\n",
    "                preprocess_data_cv = pipeline_engine.fit(Xt, yt)\n",
    "    \n",
    "                Xt = preprocess_data_cv.transform(Xt)\n",
    "                features_selected = Xt.columns\n",
    "                Xv = preprocess_data_cv.transform(Xv)\n",
    "            learner.fit(Xt[features_selected], yt.values)\n",
    "            prediction = pd.Series(learner.predict(Xv[features_selected]), index=Xv.index)   \n",
    "            mape_fold =  mean_absolute_percentage_error(yv, prediction)\n",
    "            mape_metric.append(mape_fold)\n",
    "            print(f'Fold {fold}: Best mape score: {mape_fold}')\n",
    "                                 \n",
    "        mape_opt = np.mean(mape_metric)\n",
    "        \n",
    "        result[i] = [mape_opt]\n",
    "    result = pd.DataFrame(result, columns=[\"MAPE\"],index = list(models.keys()))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:38.379198Z",
     "iopub.status.busy": "2023-09-13T01:48:38.378765Z",
     "iopub.status.idle": "2023-09-13T01:48:38.403108Z",
     "shell.execute_reply": "2023-09-13T01:48:38.402129Z",
     "shell.execute_reply.started": "2023-09-13T01:48:38.379170Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T02:30:41.298438Z",
     "iopub.status.busy": "2023-09-13T02:30:41.297940Z",
     "iopub.status.idle": "2023-09-13T02:30:41.306770Z",
     "shell.execute_reply": "2023-09-13T02:30:41.304875Z",
     "shell.execute_reply.started": "2023-09-13T02:30:41.298392Z"
    }
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LGBM': LGBMRegressor(random_state=random_state),\n",
    "    'LGBM_Poisson': LGBMRegressor(random_state=random_state, objective='poisson'),\n",
    "    'LGBM_Mape': LGBMRegressor(random_state=random_state, objective='mape'),\n",
    "    'LGBM_quantile': LGBMRegressor(random_state=random_state, objective='quantile'),\n",
    "    'LinearRegression' : LinearRegression(),\n",
    "    'PoissonRegression': linear_model.PoissonRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:38.421218Z",
     "iopub.status.busy": "2023-09-13T01:48:38.420557Z",
     "iopub.status.idle": "2023-09-13T01:48:38.440804Z",
     "shell.execute_reply": "2023-09-13T01:48:38.439582Z",
     "shell.execute_reply.started": "2023-09-13T01:48:38.421179Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_plot = x_train.columns[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:38.442931Z",
     "iopub.status.busy": "2023-09-13T01:48:38.442298Z",
     "iopub.status.idle": "2023-09-13T01:48:40.555136Z",
     "shell.execute_reply": "2023-09-13T01:48:40.554094Z",
     "shell.execute_reply.started": "2023-09-13T01:48:38.442883Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.line(train, x='fecha', y=\"total_calls\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:40.557264Z",
     "iopub.status.busy": "2023-09-13T01:48:40.556675Z",
     "iopub.status.idle": "2023-09-13T01:48:40.781407Z",
     "shell.execute_reply": "2023-09-13T01:48:40.780355Z",
     "shell.execute_reply.started": "2023-09-13T01:48:40.557231Z"
    }
   },
   "outputs": [],
   "source": [
    "for column_i in columns_to_plot:\n",
    "    fig = px.line(train, x='fecha', y=column_i)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:40.785625Z",
     "iopub.status.busy": "2023-09-13T01:48:40.784925Z",
     "iopub.status.idle": "2023-09-13T01:48:49.302012Z",
     "shell.execute_reply": "2023-09-13T01:48:49.300909Z",
     "shell.execute_reply.started": "2023-09-13T01:48:40.785588Z"
    }
   },
   "outputs": [],
   "source": [
    "train_get_score_cv(x_train=x_train.drop('fecha', axis=1),\n",
    "                   y_train=y_train,\n",
    "                   models=models,\n",
    "                   k=8,\n",
    "                   pipeline_engine=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:49.305668Z",
     "iopub.status.busy": "2023-09-13T01:48:49.303993Z",
     "iopub.status.idle": "2023-09-13T01:48:49.312817Z",
     "shell.execute_reply": "2023-09-13T01:48:49.311717Z",
     "shell.execute_reply.started": "2023-09-13T01:48:49.305626Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LGBMRegressor(random_state=random_state, objective='quantile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:49.316405Z",
     "iopub.status.busy": "2023-09-13T01:48:49.314576Z",
     "iopub.status.idle": "2023-09-13T01:48:49.776457Z",
     "shell.execute_reply": "2023-09-13T01:48:49.775567Z",
     "shell.execute_reply.started": "2023-09-13T01:48:49.316344Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x_train.drop('fecha', axis=1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:48:49.782743Z",
     "iopub.status.busy": "2023-09-13T01:48:49.780313Z",
     "iopub.status.idle": "2023-09-13T01:48:49.792473Z",
     "shell.execute_reply": "2023-09-13T01:48:49.791237Z",
     "shell.execute_reply.started": "2023-09-13T01:48:49.782707Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(model.predict(test.drop('fecha', axis=1)), index=test['fecha'], columns=['total_calls'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T01:49:57.084310Z",
     "iopub.status.busy": "2023-09-13T01:49:57.083874Z",
     "iopub.status.idle": "2023-09-13T01:49:57.091773Z",
     "shell.execute_reply": "2023-09-13T01:49:57.090550Z",
     "shell.execute_reply.started": "2023-09-13T01:49:57.084276Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction.to_csv('prediction_quantile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T02:28:29.919797Z",
     "iopub.status.busy": "2023-09-13T02:28:29.919431Z",
     "iopub.status.idle": "2023-09-13T02:28:29.929978Z",
     "shell.execute_reply": "2023-09-13T02:28:29.929078Z",
     "shell.execute_reply.started": "2023-09-13T02:28:29.919769Z"
    }
   },
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AggDayofWeek(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self: object, fecha_column: str):\n",
    "        self.fecha_column = fecha_column\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X: pd.DataFrame, y=None) -> None:\n",
    "\n",
    "        X['dayofweek'] = (X[self.fecha_column].apply(lambda x: pd.to_datetime(x) + relativedelta(months=1)).dt.dayofweek\n",
    "        )\n",
    "        return X\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T02:30:06.822341Z",
     "iopub.status.busy": "2023-09-13T02:30:06.821453Z",
     "iopub.status.idle": "2023-09-13T02:30:06.830450Z",
     "shell.execute_reply": "2023-09-13T02:30:06.829276Z",
     "shell.execute_reply.started": "2023-09-13T02:30:06.822291Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "\n",
    "to_drop = ['fecha']\n",
    "drop_features = DropFeatures(features_to_drop = to_drop)\n",
    "agg_dates = AggDayofWeek(fecha_column = 'fecha')\n",
    "one_encoder = OneHotEncoder(variables = ['dayofweek'], ignore_format=True)\n",
    "lag_fet = LagFeatures()\n",
    "\n",
    "data_pipeliene = Pipeline([ ('agg_dates', agg_dates),\n",
    "                            ('drop_features', drop_features),\n",
    "                            ('StandardScaler', SklearnTransformerWrapper(StandardScaler()))\n",
    "                            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T02:30:08.925483Z",
     "iopub.status.busy": "2023-09-13T02:30:08.925035Z",
     "iopub.status.idle": "2023-09-13T02:30:21.608719Z",
     "shell.execute_reply": "2023-09-13T02:30:21.607564Z",
     "shell.execute_reply.started": "2023-09-13T02:30:08.925445Z"
    }
   },
   "outputs": [],
   "source": [
    "train_get_score_cv(x_train=x_train,\n",
    "                   y_train=y_train,\n",
    "                   models=models,\n",
    "                   k=8,\n",
    "                   pipeline_engine=data_pipeliene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T02:31:58.701446Z",
     "iopub.status.busy": "2023-09-13T02:31:58.701027Z",
     "iopub.status.idle": "2023-09-13T02:31:58.706639Z",
     "shell.execute_reply": "2023-09-13T02:31:58.705504Z",
     "shell.execute_reply.started": "2023-09-13T02:31:58.701414Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Pipeline([('data_pipeline',data_pipeliene), ('modelo', LGBMRegressor(random_state=random_state, objective='quantile'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-13T02:32:43.624850Z",
     "iopub.status.busy": "2023-09-13T02:32:43.624032Z",
     "iopub.status.idle": "2023-09-13T02:32:44.102976Z",
     "shell.execute_reply": "2023-09-13T02:32:44.101991Z",
     "shell.execute_reply.started": "2023-09-13T02:32:43.624809Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)\n",
    "prediction = pd.DataFrame(model.predict(test), index=test['fecha'], columns=['total_calls'])  \n",
    "prediction.to_csv('prediction_quantile_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
